version: '3.4'

services:
  crawler_api:
    image: news_crawler
    container_name: news_crawler_api
    command: ["python", "/app/manage.py", "runserver", "0.0.0.0:8200"]
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    volumes:
      - .:/app
    ports: 
      - 8200:8200
    logging:
      driver: json-file
      options:
        max-file: '3'
        max-size: 15m
    restart: unless-stopped
  
  redis:
    image: redis
    container_name: news_crawler_redis
    restart: always
    logging:
      driver: none
  
  crawler_worker:
    image: news_crawler
    container_name: news_crawler_worker
    env_file:
      - .env
    volumes:
      - .:/app
    command: ["celery", "-A", "app", "worker", "-l", "info", "--pidfile="]
    logging:
      driver: json-file
      options:
        max-file: '3'
        max-size: 15m
    restart: always
  
  crawler_beat:
    image: news_crawler
    container_name: news_crawler_beat
    env_file:
      - .env
    volumes:
      - .:/app
    command: ["celery", "-A", "app", "beat", "-l", "info", "--pidfile="]
    logging:
      driver: json-file
      options:
        max-file: '3'
        max-size: 15m
    restart: always
  
  crawler_chrome:
    image: selenium/standalone-chrome
    container_name: news_crawler_chrome
    logging:
      driver: none
    restart: always
